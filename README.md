# HCC Survival Analysis

A comprehensive survival analysis system for Hepatocellular Carcinoma (HCC) patients using machine learning approaches.

## Features

### ğŸ¥ Clinical Survival Analysis
- Multiple survival models: Cox Proportional Hazards, XGBoost AFT, CatBoost AFT
- Ensemble predictions across multiple random seeds for robust results
- Comprehensive evaluation metrics including C-index

### ğŸ“Š Advanced Calibration Methods
- KNN + Kaplan-Meier curve calibration
- Regression-based calibration for censored data
- Segmental calibration
- Polynomial curve calibration

### ğŸ” What-if Analysis
- Treatment modification analysis: Evaluate impact of different treatment combinations
- Continuous feature analysis: Assess effects of BMI, Age, AFP changes
- Stage-stratified analysis for personalized insights

### ğŸ“ˆ Visualization Suite
- Feature importance heatmaps and bar charts
- Calibration effect scatter plots (train/test comparison)
- K/U group metrics analysis
- Comprehensive survival prediction error analysis

### âš¡ Performance Optimization
- Multiprocessing support with configurable worker count
- Automatic CPU core allocation
- Progress tracking for long-running experiments

## Installation

### Prerequisites
- Python 3.11+
- Anaconda or Miniconda
- Poetry for dependency management

### Setup Instructions

1. **Create Conda Environment**
```bash
# Create a new conda environment with Python 3.11
conda create -n hcc_survival python=3.11
conda activate hcc_survival
```

2. **Clone Repository and Install Dependencies**
```bash
# Clone the repository
git clone https://github.com/yourusername/HCC_Survival_Analysis.git
cd HCC_Survival_Analysis

# Install dependencies using poetry
poetry install
```

3. **Verify Installation**
```bash
# Run a test to ensure everything is working
python src/main.py
```

## Project Structure

```
HCC_Survival_Analysis/
â”œâ”€â”€ config/                         # Configuration files
â”‚   â”œâ”€â”€ experiment_config.json      # Model and experiment settings
â”‚   â”œâ”€â”€ feature_config.json         # Feature definitions
â”‚   â”œâ”€â”€ multiprocess_config.json    # Multiprocessing settings
â”‚   â”œâ”€â”€ path_config.json            # File path configurations
â”‚   â””â”€â”€ preprocess_config.json      # Data preprocessing settings
â”œâ”€â”€ dataset/                        # Data directory
â”‚   â”œâ”€â”€ processed/                  # Processed datasets
â”‚   â”‚   â”œâ”€â”€ augmented/              # Augmented data
â”‚   â”‚   â””â”€â”€ imputed/                # Imputed data
â”‚   â””â”€â”€ raw/                        # Raw data files
â”‚       â””â”€â”€ hospitals/              # Hospital-specific data
â”œâ”€â”€ results/                        # Experiment results (auto-generated)
â”‚   â””â”€â”€ {timestamp}/                # Results for each run
â”‚       â”œâ”€â”€ calibration/            # Calibration analysis results
â”‚       â”œâ”€â”€ ensemble_feature_importance/
â”‚       â”œâ”€â”€ ensemble_predictions/
â”‚       â”œâ”€â”€ figures/                # Generated visualizations
â”‚       â”œâ”€â”€ metrics/                # Performance metrics
â”‚       â”œâ”€â”€ models/                 # Saved model files
â”‚       â”œâ”€â”€ original_predictions/
â”‚       â”œâ”€â”€ report.txt          
â”‚       â””â”€â”€ summary.xlsx            # Comprehensive summary
â”œâ”€â”€ src/                            # Source code
â”‚   â”œâ”€â”€ analyzing/                  # Analysis modules
â”‚   â”‚   â”œâ”€â”€ ensemble_analyzer.py
â”‚   â”‚   â””â”€â”€ visualizer.py
â”‚   â”œâ”€â”€ experimenting/              # Experiment execution
â”‚   â”‚   â””â”€â”€ experimentor.py
â”‚   â”œâ”€â”€ preprocessing/              # Data preprocessing
â”‚   â”‚   â””â”€â”€ preprocessor.py
â”‚   â”œâ”€â”€ utils/                      # Utility modules
â”‚   â”‚   â”œâ”€â”€ config_utils.py
â”‚   â”‚   â””â”€â”€ multiprocess_utils.py
â”‚   â””â”€â”€ main.py                     # Main entry point
â”œâ”€â”€ LICENSE                         # MIT License
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ poetry.lock                     # Poetry lock file
â””â”€â”€ pyproject.toml                  # Project dependencies
```

## Usage

### Basic Usage

1. **Prepare your data**
   - Place your dataset in `dataset/raw/`
   - Update `config/path_config.json` with your file names

2. **Configure experiment**
   - Edit `config/experiment_config.json` to set:
     - Number of experiments (random seeds)
     - Models to train
     - Calibration methods to apply

3. **Run analysis**
```bash
python src/main.py
```

### Configuration Options

#### Multiprocessing Settings (`config/multiprocess_config.json`)
```json
{
  "enabled": true,           # Enable/disable multiprocessing
  "max_workers": 4,          # Maximum number of CPU cores
  "use_cpu_count": true,     # Auto-detect optimal core count
  "reserve_cpus": 1          # CPUs to reserve for system
}
```

#### Model Settings (`config/experiment_config.json`)
- `num_experiments`: Number of random seeds for ensemble
- `models_to_train`: List of models to use
- `test_size`: Train/test split ratio
- `calibration_methods`: Calibration techniques to apply

### Output

Results are saved in `results/{timestamp}/` including:
- **summary.xlsx**: Comprehensive performance summary
- **figures/**: All generated visualizations
- **models/**: Trained model pickle files
- **ensemble_predictions/**: Aggregated predictions
- **metrics/**: Detailed performance metrics

## Key Components

### Models
- **CoxPHFitter**: Traditional Cox Proportional Hazards model
- **XGBoost_AFT**: Accelerated Failure Time model with gradient boosting
- **CatBoost_AFT**: CatBoost implementation for survival analysis

### Calibration Methods
- **knn_km**: K-nearest neighbors with Kaplan-Meier estimation
- **regression**: Linear regression on non-censored data
- **segmental**: Segment-based bias correction
- **curve**: Polynomial curve fitting for calibration

### Analysis Features
- Feature importance analysis using SHAP values
- Ensemble predictions across multiple seeds
- Comprehensive error analysis for censored/non-censored groups
- What-if scenario analysis for treatment planning

## Citation

If you use this software in your research, please cite:

```bibtex
@software{hcc_survival_analysis,
  title = {HCC Survival Analysis: Machine Learning for Hepatocellular Carcinoma Prognosis},
  author = {Yu-Ren Jhuang},
  year = {2025},
  url = {https://github.com/a7266165/HCC_Survival_Analysis}
}
```

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Thanks to all contributors and collaborators
- Special thanks to the medical teams providing domain expertise
- Built with love for improving patient outcomes ğŸ’